#!/usr/bin/env python3
"""
ë‹¤ì–‘í•œ ë°ì´í„°ì…‹ êµ¬ì¡°ë¥¼ ìë™ ê°ì§€í•˜ì—¬ train/validationìœ¼ë¡œ ë¶„í• í•˜ëŠ” ìŠ¤í¬ë¦½íŠ¸
ì›ë³¸ ë°ì´í„°ì…‹ì˜ images/train, images/valì— ì§ì ‘ ì €ì¥
"""

import os
import shutil
import random
import argparse
from pathlib import Path
from typing import List, Tuple, Optional

def get_image_files(folder_path: str) -> List[str]:
    """í´ë”ì—ì„œ ì´ë¯¸ì§€ íŒŒì¼ë“¤ì„ ê°€ì ¸ì˜µë‹ˆë‹¤."""
    image_extensions = {'.jpg', '.jpeg', '.png', '.bmp', '.tiff', '.webp', '.gif'}
    folder_path = Path(folder_path)
    image_files = []
    
    if not folder_path.exists():
        return image_files
    
    for file_path in folder_path.iterdir():
        if file_path.is_file() and file_path.suffix.lower() in image_extensions:
            image_files.append(str(file_path))
    
    return image_files

def detect_dataset_structure(dataset_path: str) -> Tuple[Optional[str], Optional[str], Optional[str]]:
    """ë°ì´í„°ì…‹ êµ¬ì¡°ë¥¼ ìë™ìœ¼ë¡œ ê°ì§€í•©ë‹ˆë‹¤."""
    dataset_path = Path(dataset_path)
    
    # êµ¬ì¡° 1: dataset/images/train, dataset/images/val
    images_train = dataset_path / 'images' / 'train'
    images_val = dataset_path / 'images' / 'val'
    if images_train.exists() or images_val.exists():
        return 'images_trainval', str(images_train), str(images_val)
    
    # êµ¬ì¡° 2: dataset/train, dataset/val
    train_dir = dataset_path / 'train'
    val_dir = dataset_path / 'val'
    if train_dir.exists() or val_dir.exists():
        return 'trainval', str(train_dir), str(val_dir)
    
    # êµ¬ì¡° 3: dataset/images/ (ë‹¨ì¼ í´ë”)
    images_dir = dataset_path / 'images'
    if images_dir.exists() and get_image_files(images_dir):
        return 'images_only', str(images_dir), None
    
    # êµ¬ì¡° 4: dataset/ (ì´ë¯¸ì§€ íŒŒì¼ë“¤ì´ ì§ì ‘ ìˆëŠ” ê²½ìš°)
    if get_image_files(dataset_path):
        return 'direct', str(dataset_path), None
    
    return None, None, None

def split_files(files: List[str], val_ratio: float) -> Tuple[List[str], List[str]]:
    """íŒŒì¼ ë¦¬ìŠ¤íŠ¸ë¥¼ train/validationìœ¼ë¡œ ë¶„í• í•©ë‹ˆë‹¤."""
    random.shuffle(files)
    val_count = int(len(files) * val_ratio)
    
    val_files = files[:val_count]
    train_files = files[val_count:]
    
    return train_files, val_files

def image_to_label_path(img_path: Path, dataset_root: Path) -> Path:
    """
    images/.../abc.jpg  ->  labels/.../abc.txt
    """
    rel = img_path.relative_to(dataset_root / 'images')
    return dataset_root / 'labels' / rel.with_suffix('.txt')

def move_with_labels(img_list: List[str], dst_img_dir: Path, dst_lbl_dir: Path, dataset_root: Path, move: bool = True):
    """ì´ë¯¸ì§€ì™€ ë¼ë²¨ì„ í•¨ê»˜ ì´ë™/ë³µì‚¬í•©ë‹ˆë‹¤."""
    processed = 0
    action = "ì´ë™" if move else "ë³µì‚¬"
    
    dst_img_dir.mkdir(parents=True, exist_ok=True)
    dst_lbl_dir.mkdir(parents=True, exist_ok=True)
    
    print(f"  ğŸ“ ì´ë¯¸ì§€ í´ë”: {dst_img_dir}")
    print(f"  ğŸ“ ë¼ë²¨ í´ë”: {dst_lbl_dir}")
    print(f"  ğŸ“‹ ì²˜ë¦¬í•  íŒŒì¼ ìˆ˜: {len(img_list)}ê°œ")
    
    for i, img in enumerate(img_list):
        src_img = Path(img)
        src_lbl = image_to_label_path(src_img, dataset_root)
        dst_img = dst_img_dir / src_img.name
        dst_lbl = dst_lbl_dir / src_lbl.name
        
        try:
            # ì´ë¯¸ì§€ ì´ë™/ë³µì‚¬
            if move:
                shutil.move(str(src_img), str(dst_img))
            else:
                shutil.copy2(src_img, dst_img)
            
            # ë¼ë²¨ ì´ë™/ë³µì‚¬ (ì—†ìœ¼ë©´ ë¹ˆ txt ìƒì„±)
            if src_lbl.exists():
                if move:
                    shutil.move(str(src_lbl), str(dst_lbl))
                else:
                    shutil.copy2(src_lbl, dst_lbl)
            else:
                dst_lbl.touch()  # negative sample
            
            processed += 1
            
            # ì²˜ë¦¬ ì§„í–‰ë¥  í‘œì‹œ (10ê°œë§ˆë‹¤)
            if (i + 1) % 10 == 0 or (i + 1) == len(img_list):
                print(f"  âœ… {action} ì™„ë£Œ: {processed}/{len(img_list)}ê°œ")
                
        except Exception as e:
            print(f"âš ï¸  {action} ì‹¤íŒ¨: {src_img} -> {e}")
    
    print(f"  ğŸ¯ ìµœì¢… {action} ì™„ë£Œ: {processed}ê°œ")
    return processed

def main():
    parser = argparse.ArgumentParser(description='ë°ì´í„°ì…‹ì„ ì›ë³¸ ê²½ë¡œì˜ images/train, images/valì— ë¶„í• ')
    parser.add_argument('dataset_path', help='ë°ì´í„°ì…‹ ê²½ë¡œ')
    parser.add_argument('--val-ratio', type=float, default=0.2, 
                       help='validation ë¹„ìœ¨ (ê¸°ë³¸ê°’: 0.2)')
    parser.add_argument('--seed', type=int, default=42, 
                       help='ëœë¤ ì‹œë“œ (ê¸°ë³¸ê°’: 42)')
    parser.add_argument('--copy', action='store_true', 
                       help='íŒŒì¼ì„ ë³µì‚¬í•©ë‹ˆë‹¤ (ê¸°ë³¸ê°’: ì´ë™)')
    
    args = parser.parse_args()
    
    # ì´ë™/ë³µì‚¬ ëª¨ë“œ ê²°ì • (ê¸°ë³¸ê°’: ì´ë™)
    move_mode = not args.copy
    
    # ëœë¤ ì‹œë“œ ì„¤ì •
    random.seed(args.seed)
    
    # ê²½ë¡œ ì„¤ì •
    dataset_path = Path(args.dataset_path)
    
    # ë°ì´í„°ì…‹ ê²½ë¡œ í™•ì¸
    if not dataset_path.exists():
        print(f"âŒ ë°ì´í„°ì…‹ ê²½ë¡œê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: {dataset_path}")
        return
    
    # ë°ì´í„°ì…‹ êµ¬ì¡° ìë™ ê°ì§€
    print(f"ğŸ” ë°ì´í„°ì…‹ êµ¬ì¡° ê°ì§€ ì¤‘: {dataset_path}")
    structure_type, train_path, val_path = detect_dataset_structure(args.dataset_path)
    
    if structure_type is None:
        print(f"âŒ ì§€ì›í•˜ëŠ” ë°ì´í„°ì…‹ êµ¬ì¡°ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        print(f"ì§€ì›í•˜ëŠ” êµ¬ì¡°:")
        print(f"  1. {dataset_path}/images/train, {dataset_path}/images/val")
        print(f"  2. {dataset_path}/train, {dataset_path}/val")
        print(f"  3. {dataset_path}/images/ (ì´ë¯¸ì§€ íŒŒì¼ë“¤)")
        print(f"  4. {dataset_path}/ (ì´ë¯¸ì§€ íŒŒì¼ë“¤)")
        return
    
    # ì¶œë ¥ ê²½ë¡œë¥¼ ì›ë³¸ ë°ì´í„°ì…‹ì˜ images/train, images/valë¡œ ì„¤ì •
    output_train_img_path = dataset_path / 'images' / 'train'
    output_val_img_path = dataset_path / 'images' / 'val'
    output_train_lbl_path = dataset_path / 'labels' / 'train'
    output_val_lbl_path = dataset_path / 'labels' / 'val'
    
    # ì¶œë ¥ í´ë” ìƒì„±
    try:
        output_train_img_path.mkdir(parents=True, exist_ok=True)
        output_val_img_path.mkdir(parents=True, exist_ok=True)
        output_train_lbl_path.mkdir(parents=True, exist_ok=True)
        output_val_lbl_path.mkdir(parents=True, exist_ok=True)
        print(f"ğŸ“ ì¶œë ¥ í´ë” í™•ì¸/ìƒì„±: {dataset_path}/images/, {dataset_path}/labels/")
    except Exception as e:
        print(f"âŒ ì¶œë ¥ í´ë” ìƒì„± ì‹¤íŒ¨: {dataset_path} -> {e}")
        return
    
    # êµ¬ì¡°ë³„ ì²˜ë¦¬
    all_files = []
    
    if structure_type == 'images_trainval':
        print(f"ğŸ“ ê°ì§€ëœ êµ¬ì¡°: images/train, images/val")
        train_files = get_image_files(train_path) if Path(train_path).exists() else []
        val_files = get_image_files(val_path) if Path(val_path).exists() else []
        all_files = train_files + val_files
        print(f"ğŸ–¼ï¸  ê¸°ì¡´ Train: {len(train_files)}ê°œ, Val: {len(val_files)}ê°œ")
        
    elif structure_type == 'trainval':
        print(f"ğŸ“ ê°ì§€ëœ êµ¬ì¡°: train, val")
        train_files = get_image_files(train_path) if Path(train_path).exists() else []
        val_files = get_image_files(val_path) if Path(val_path).exists() else []
        all_files = train_files + val_files
        print(f"ğŸ–¼ï¸  ê¸°ì¡´ Train: {len(train_files)}ê°œ, Val: {len(val_files)}ê°œ")
        
    elif structure_type == 'images_only':
        print(f"ğŸ“ ê°ì§€ëœ êµ¬ì¡°: images/ (ë‹¨ì¼ í´ë”)")
        all_files = get_image_files(train_path)  # train_pathê°€ images í´ë” ê²½ë¡œ
        print(f"ğŸ–¼ï¸  ì „ì²´ ì´ë¯¸ì§€: {len(all_files)}ê°œ")
        
    elif structure_type == 'direct':
        print(f"ğŸ“ ê°ì§€ëœ êµ¬ì¡°: ì§ì ‘ ì´ë¯¸ì§€ íŒŒì¼ë“¤")
        all_files = get_image_files(train_path)  # train_pathê°€ dataset í´ë” ê²½ë¡œ
        print(f"ğŸ–¼ï¸  ì „ì²´ ì´ë¯¸ì§€: {len(all_files)}ê°œ")
    
    if not all_files:
        print(f"âŒ ì´ë¯¸ì§€ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return
    
    print(f"ğŸ–¼ï¸  ì´ ì´ë¯¸ì§€: {len(all_files)}ê°œ")
    print(f"ğŸ“Š ìƒˆë¡œìš´ Validation ë¹„ìœ¨: {args.val_ratio:.1%}")
    print(f"ğŸ“¤ ì¶œë ¥ ê²½ë¡œ: {dataset_path}/images/, {dataset_path}/labels/")
    print(f"ğŸ”„ ëª¨ë“œ: {'ì´ë™' if move_mode else 'ë³µì‚¬'}")
    print("-" * 60)
    
    # ìƒˆë¡œìš´ ë¹„ìœ¨ë¡œ ë¶„í• 
    new_train_files, new_val_files = split_files(all_files, args.val_ratio)
    
    print(f"ğŸš‚ ìƒˆë¡œìš´ Train ì´ë¯¸ì§€: {len(new_train_files)}ê°œ")
    print(f"âœ… ìƒˆë¡œìš´ Validation ì´ë¯¸ì§€: {len(new_val_files)}ê°œ")
    print("-" * 60)
    
    # íŒŒì¼ ì²˜ë¦¬ (ì´ë¯¸ì§€ + ë¼ë²¨)
    action_word = "ì´ë™" if move_mode else "ë³µì‚¬"
    print(f"ğŸ“‹ Train ì´ë¯¸ì§€+ë¼ë²¨ {action_word} ì¤‘...")
    train_processed = move_with_labels(new_train_files, output_train_img_path, output_train_lbl_path, dataset_path, move_mode)
    
    print(f"ğŸ“‹ Validation ì´ë¯¸ì§€+ë¼ë²¨ {action_word} ì¤‘...")
    val_processed = move_with_labels(new_val_files, output_val_img_path, output_val_lbl_path, dataset_path, move_mode)
    
    print("-" * 60)
    print(f"ğŸ‰ ì¬ë¶„í•  ì™„ë£Œ!")
    print(f"ğŸ“Š ì´ ì´ë¯¸ì§€: {len(all_files)}ê°œ")
    print(f"ğŸš‚ Train: {train_processed}ê°œ {action_word} â†’ {output_train_img_path}")
    print(f"âœ… Validation: {val_processed}ê°œ {action_word} â†’ {output_val_img_path}")
    print(f"ğŸ·ï¸  ë¼ë²¨ë„ í•¨ê»˜ ì²˜ë¦¬ë¨ â†’ {output_train_lbl_path}, {output_val_lbl_path}")
    
    # ì‹¤ì œ ë¹„ìœ¨ ê³„ì‚°
    total_processed = train_processed + val_processed
    if total_processed > 0:
        actual_train_ratio = train_processed / total_processed
        actual_val_ratio = val_processed / total_processed
        print(f"ğŸ“ˆ ì‹¤ì œ ë¹„ìœ¨ - Train: {actual_train_ratio:.1%}, Val: {actual_val_ratio:.1%}")
            
    if move_mode:
        print(f"âš ï¸  ì›ë³¸ íŒŒì¼ë“¤ì´ ì´ë™ë˜ì—ˆìŠµë‹ˆë‹¤. ë°±ì—…ì´ í•„ìš”í•œ ê²½ìš° --copy ì˜µì…˜ì„ ì‚¬ìš©í•˜ì„¸ìš”.")

if __name__ == "__main__":
    main()